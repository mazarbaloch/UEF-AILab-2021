{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import sys"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "# read the data set\n",
    "df = pd.read_csv('../data/breast-cancer.txt')\n",
    "\n",
    "# Replace the missing or non numeric values\n",
    "df.dropna(inplace=True)\n",
    "df=df._get_numeric_data()\n",
    "\n",
    "\n",
    "\n",
    "# Drop the ID column\n",
    "df.drop(['id'], 1, inplace=True)\n",
    "# Create features and labels arrays\n",
    "X = np.array(df.drop(['class'], 1))\n",
    "y = np.array(df['class'])\n",
    "# Scale the features array X\n",
    "# The scaling of the data is important for convergence of the model\n",
    "# There are different types of scaling\n",
    "scaler1 = MinMaxScaler(feature_range=(0,1))\n",
    "scaler1.fit(X)\n",
    "X = scaler1.transform(X)\n",
    "\n",
    "# scaler2 = StandardScaler()\n",
    "# scaler2.fit(X)\n",
    "# X = scaler2.transform(X)\n",
    "\n",
    "# Transform the feature array y to a binary array 0 or 1\n",
    "y = np.array(y==4).astype(int)\n",
    "\n",
    "# Split the arrays into training and test arrays\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "print(X_train,X_test, y_train, y_test)\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.66666667 0.11111111 0.33333333 ... 0.44444444 0.33333333 0.22222222]\n",
      " [1.         1.         1.         ... 1.         1.         0.66666667]\n",
      " [0.33333333 0.         0.         ... 0.11111111 0.         0.        ]\n",
      " ...\n",
      " [0.11111111 0.         0.         ... 0.11111111 0.         0.        ]\n",
      " [0.88888889 0.77777778 0.77777778 ... 0.33333333 1.         0.33333333]\n",
      " [0.         0.         0.11111111 ... 0.11111111 0.         0.        ]] [[0.11111111 0.44444444 0.22222222 ... 0.66666667 0.44444444 0.        ]\n",
      " [0.77777778 0.22222222 0.44444444 ... 0.         0.55555556 0.11111111]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [1.         0.33333333 0.22222222 ... 0.55555556 0.44444444 0.11111111]\n",
      " [0.22222222 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.33333333 0.         0.22222222 ... 0.11111111 0.         0.        ]] [1 1 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 1 0 1 0 0 1 0 1 0 1 1 0 0 1\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 0 1 1 0\n",
      " 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 1 1 1 0 0 0 1\n",
      " 1 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 0 1 1 0 0 1 0 0\n",
      " 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0\n",
      " 1 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0\n",
      " 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 1 1 1 0 1 1 1 1 0 1\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 1 1 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 1 0 1 0 0 1 0 1 0 1\n",
      " 0 0 1 0 1 0 1 0 1 0 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 1 1 0 0 0 0 1 1 0 0 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 1 0 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1\n",
      " 0 1 0 0 0 0 1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 1 0 0 1 1 0 1\n",
      " 0 0 1 1 1 0 1 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 1 0 1 1 0 1 0 0\n",
      " 0 0 1 0] [1 1 0 0 0 0 0 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 0 0 1 0 1 0 1 0 1 0 0 1 1 0\n",
      " 0 1 1 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1\n",
      " 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 1 0 1 0 0 0 0 0 1 0 0]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/mazhar/anaconda3/envs/AICourse/lib/python3.7/site-packages/ipykernel_launcher.py:15: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/mazhar/anaconda3/envs/AICourse/lib/python3.7/site-packages/ipykernel_launcher.py:17: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "np.save('X_train.npy',X_train)\n",
    "np.save('X_test.npy', X_test)\n",
    "np.save('y_train.npy',y_train)\n",
    "np.save('y_test.npy', y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "print(np.load('X_train.npy'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('AICourse': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "interpreter": {
   "hash": "b08ff39e81487ac2de0ed1ab81ce70dc789eff7d4d49b530beb9695a7fce355d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}